{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP - Summary Generator\n",
    "\n",
    "Lots of example code taken from: https://machinelearningmastery.com/develop-character-based-neural-language-model-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./processed_data/fantasy_book_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of summaries: 16559\n"
     ]
    }
   ],
   "source": [
    "summary_data = list(data['summaries'])\n",
    "# summary_data[0]\n",
    "print('Number of summaries: %d' % (len(summary_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 11.00\n",
      "Max: 58019.00\n",
      "Mean: 2511.11\n",
      "Stdev: 2902.99\n"
     ]
    }
   ],
   "source": [
    "summary_lengths = [len(s) for s in summary_data]\n",
    "mean_chars = np.mean(np.array(summary_lengths))\n",
    "stdev_chars = np.std(np.array(summary_lengths))\n",
    "max_chars = max(summary_lengths)\n",
    "min_chars = min(summary_lengths)\n",
    "print(\"Min: {:.2f}\".format(min_chars))\n",
    "print(\"Max: {:.2f}\".format(max_chars))\n",
    "print(\"Mean: {:.2f}\".format(mean_chars))\n",
    "print(\"Stdev: {:.2f}\".format(stdev_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "# stops.extend('.,[,],(,),;,/,-,\\',?,\",:,<,>,n\\'t,|,#,\\'s,\\\",\\'re,\\'ve,\\'ll,\\'d,\\'re'.split(','))\n",
    "# stops.extend(',')\n",
    "\n",
    "chars = []\n",
    "unknown_label = 'UNK'\n",
    "\n",
    "char_dict = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789 .!?:,\\'%-\\(\\)/$|&;[]\"'\n",
    "\n",
    "for c in char_dict:\n",
    "    chars.append(c)\n",
    "\n",
    "chars = list(set(chars))\n",
    "\n",
    "chars.insert(0, unknown_label)\n",
    "\n",
    "mapping = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_chars = []\n",
    "summary_data_cleaned = []\n",
    "# encoded_summary_data = []\n",
    "\n",
    "sequences = []\n",
    "\n",
    "for i, summary in enumerate(summary_data):\n",
    "#     filtered_summary = \" \".join([w for w in word_tokenize(summary) if not w.lower() in stops])\n",
    "    filtered_summary = (summary).strip()\n",
    "    if len(filtered_summary) < seq_length + 1:\n",
    "        continue\n",
    "    summary_chars = [c if c in chars else 'UNK' for c in summary]\n",
    "    filtered_summary = \"\".join(summary_chars)\n",
    "#     encoded_summary_chars = [mapping[c] for c in summary_chars]\n",
    "    unknown_chars = list(set(unknown_chars + [c for c in summary if c not in chars]))\n",
    "    summary_data_cleaned.append(summary_chars)\n",
    "\n",
    "    for j in range(seq_length, len(summary_chars)):\n",
    "        # select sequence of tokens\n",
    "        seq = filtered_summary[j-seq_length:j+1]\n",
    "        sequences.append(seq)\n",
    "#     encoded_summary_data.append(encoded_summary_chars)\n",
    "        \n",
    "    if i >= 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 60942\n"
     ]
    }
   ],
   "source": [
    "# len(summary_data_cleaned)\n",
    "print('Total Sequences: %d' % len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequences = 1000\n",
    "encoded_sequences = []\n",
    "for i, s in enumerate(sequences):\n",
    "    if i >= max_sequences:\n",
    "        break\n",
    "    encoded_seq = [mapping[c] for c in s]\n",
    "    encoded_sequences.append(encoded_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_sequences = np.array(encoded_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = encoded_sequences[:,:-1], encoded_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [to_categorical(x, num_classes=vocab_size) for x in X]\n",
    "X = np.array(X)\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 200, 83)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 75)                47700     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 83)                6308      \n",
      "=================================================================\n",
      "Total params: 54,008\n",
      "Trainable params: 54,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      " - 7s - loss: 3.9580 - accuracy: 0.0770\n",
      "Epoch 2/100\n",
      " - 6s - loss: 3.1201 - accuracy: 0.1590\n",
      "Epoch 3/100\n",
      " - 6s - loss: 3.0470 - accuracy: 0.1590\n",
      "Epoch 4/100\n",
      " - 6s - loss: 3.0362 - accuracy: 0.1590\n",
      "Epoch 5/100\n",
      " - 7s - loss: 3.0291 - accuracy: 0.1590\n",
      "Epoch 6/100\n",
      " - 6s - loss: 3.0142 - accuracy: 0.1590\n",
      "Epoch 7/100\n",
      " - 6s - loss: 3.0024 - accuracy: 0.1590\n",
      "Epoch 8/100\n",
      " - 6s - loss: 2.9890 - accuracy: 0.1590\n",
      "Epoch 9/100\n",
      " - 6s - loss: 2.9737 - accuracy: 0.1590\n",
      "Epoch 10/100\n",
      " - 6s - loss: 2.9617 - accuracy: 0.1630\n",
      "Epoch 11/100\n",
      " - 6s - loss: 2.9424 - accuracy: 0.1590\n",
      "Epoch 12/100\n",
      " - 6s - loss: 2.9256 - accuracy: 0.1590\n",
      "Epoch 13/100\n",
      " - 7s - loss: 2.9021 - accuracy: 0.1630\n",
      "Epoch 14/100\n",
      " - 6s - loss: 2.8710 - accuracy: 0.1810\n",
      "Epoch 15/100\n",
      " - 6s - loss: 2.8409 - accuracy: 0.2010\n",
      "Epoch 16/100\n",
      " - 6s - loss: 2.8086 - accuracy: 0.2050\n",
      "Epoch 17/100\n",
      " - 6s - loss: 2.7813 - accuracy: 0.2390\n",
      "Epoch 18/100\n",
      " - 6s - loss: 2.7418 - accuracy: 0.2520\n",
      "Epoch 19/100\n",
      " - 6s - loss: 2.6991 - accuracy: 0.2850\n",
      "Epoch 20/100\n",
      " - 6s - loss: 2.6643 - accuracy: 0.2930\n",
      "Epoch 21/100\n",
      " - 6s - loss: 2.6325 - accuracy: 0.2880\n",
      "Epoch 22/100\n",
      " - 6s - loss: 2.6020 - accuracy: 0.3050\n",
      "Epoch 23/100\n",
      " - 6s - loss: 2.5754 - accuracy: 0.3120\n",
      "Epoch 24/100\n",
      " - 6s - loss: 2.5438 - accuracy: 0.3250\n",
      "Epoch 25/100\n",
      " - 6s - loss: 2.5214 - accuracy: 0.3300\n",
      "Epoch 26/100\n",
      " - 6s - loss: 2.4895 - accuracy: 0.3310\n",
      "Epoch 27/100\n",
      " - 6s - loss: 2.4719 - accuracy: 0.3360\n",
      "Epoch 28/100\n",
      " - 6s - loss: 2.4507 - accuracy: 0.3430\n",
      "Epoch 29/100\n",
      " - 6s - loss: 2.4247 - accuracy: 0.3480\n",
      "Epoch 30/100\n",
      " - 6s - loss: 2.4095 - accuracy: 0.3470\n",
      "Epoch 31/100\n",
      " - 6s - loss: 2.3809 - accuracy: 0.3540\n",
      "Epoch 32/100\n",
      " - 6s - loss: 2.3625 - accuracy: 0.3590\n",
      "Epoch 33/100\n",
      " - 6s - loss: 2.3381 - accuracy: 0.3550\n",
      "Epoch 34/100\n",
      " - 6s - loss: 2.3365 - accuracy: 0.3670\n",
      "Epoch 35/100\n",
      " - 6s - loss: 2.3167 - accuracy: 0.3720\n",
      "Epoch 36/100\n",
      " - 6s - loss: 2.2913 - accuracy: 0.3710\n",
      "Epoch 37/100\n",
      " - 6s - loss: 2.2707 - accuracy: 0.3740\n",
      "Epoch 38/100\n",
      " - 6s - loss: 2.2526 - accuracy: 0.3750\n",
      "Epoch 39/100\n",
      " - 6s - loss: 2.2326 - accuracy: 0.3910\n",
      "Epoch 40/100\n",
      " - 6s - loss: 2.2140 - accuracy: 0.3900\n",
      "Epoch 41/100\n",
      " - 6s - loss: 2.2053 - accuracy: 0.3780\n",
      "Epoch 42/100\n",
      " - 6s - loss: 2.1854 - accuracy: 0.3960\n",
      "Epoch 43/100\n",
      " - 6s - loss: 2.1737 - accuracy: 0.4010\n",
      "Epoch 44/100\n",
      " - 6s - loss: 2.1539 - accuracy: 0.3970\n",
      "Epoch 45/100\n",
      " - 6s - loss: 2.1374 - accuracy: 0.4200\n",
      "Epoch 46/100\n",
      " - 6s - loss: 2.1220 - accuracy: 0.4150\n",
      "Epoch 47/100\n",
      " - 6s - loss: 2.1001 - accuracy: 0.4230\n",
      "Epoch 48/100\n",
      " - 6s - loss: 2.0958 - accuracy: 0.4160\n",
      "Epoch 49/100\n",
      " - 6s - loss: 2.0733 - accuracy: 0.4370\n",
      "Epoch 50/100\n",
      " - 6s - loss: 2.0618 - accuracy: 0.4300\n",
      "Epoch 51/100\n",
      " - 6s - loss: 2.0498 - accuracy: 0.4330\n",
      "Epoch 52/100\n",
      " - 6s - loss: 2.0420 - accuracy: 0.4340\n",
      "Epoch 53/100\n",
      " - 6s - loss: 2.0214 - accuracy: 0.4350\n",
      "Epoch 54/100\n",
      " - 6s - loss: 2.0071 - accuracy: 0.4440\n",
      "Epoch 55/100\n",
      " - 6s - loss: 1.9864 - accuracy: 0.4460\n",
      "Epoch 56/100\n",
      " - 7s - loss: 1.9842 - accuracy: 0.4440\n",
      "Epoch 57/100\n",
      " - 6s - loss: 1.9691 - accuracy: 0.4540\n",
      "Epoch 58/100\n",
      " - 6s - loss: 1.9617 - accuracy: 0.4470\n",
      "Epoch 59/100\n",
      " - 6s - loss: 1.9424 - accuracy: 0.4590\n",
      "Epoch 60/100\n",
      " - 6s - loss: 1.9249 - accuracy: 0.4630\n",
      "Epoch 61/100\n",
      " - 6s - loss: 1.9103 - accuracy: 0.4590\n",
      "Epoch 62/100\n",
      " - 6s - loss: 1.8955 - accuracy: 0.4660\n",
      "Epoch 63/100\n",
      " - 6s - loss: 1.8838 - accuracy: 0.4620\n",
      "Epoch 64/100\n",
      " - 6s - loss: 1.8803 - accuracy: 0.4760\n",
      "Epoch 65/100\n",
      " - 6s - loss: 1.8582 - accuracy: 0.4790\n",
      "Epoch 66/100\n",
      " - 6s - loss: 1.8446 - accuracy: 0.4790\n",
      "Epoch 67/100\n",
      " - 6s - loss: 1.8301 - accuracy: 0.4780\n",
      "Epoch 68/100\n",
      " - 6s - loss: 1.8193 - accuracy: 0.4770\n",
      "Epoch 69/100\n",
      " - 6s - loss: 1.8068 - accuracy: 0.4890\n",
      "Epoch 70/100\n",
      " - 6s - loss: 1.7865 - accuracy: 0.4920\n",
      "Epoch 71/100\n",
      " - 6s - loss: 1.7812 - accuracy: 0.5020\n",
      "Epoch 72/100\n",
      " - 6s - loss: 1.7695 - accuracy: 0.4890\n",
      "Epoch 73/100\n",
      " - 6s - loss: 1.7614 - accuracy: 0.4960\n",
      "Epoch 74/100\n",
      " - 6s - loss: 1.7483 - accuracy: 0.4820\n",
      "Epoch 75/100\n",
      " - 6s - loss: 1.7231 - accuracy: 0.4950\n",
      "Epoch 76/100\n",
      " - 6s - loss: 1.7168 - accuracy: 0.5050\n",
      "Epoch 77/100\n",
      " - 6s - loss: 1.7033 - accuracy: 0.5120\n",
      "Epoch 78/100\n",
      " - 6s - loss: 1.6923 - accuracy: 0.5160\n",
      "Epoch 79/100\n",
      " - 6s - loss: 1.6881 - accuracy: 0.5180\n",
      "Epoch 80/100\n",
      " - 6s - loss: 1.6694 - accuracy: 0.5220\n",
      "Epoch 81/100\n",
      " - 6s - loss: 1.6660 - accuracy: 0.5160\n",
      "Epoch 82/100\n",
      " - 6s - loss: 1.6459 - accuracy: 0.5250\n",
      "Epoch 83/100\n",
      " - 6s - loss: 1.6318 - accuracy: 0.5250\n",
      "Epoch 84/100\n",
      " - 6s - loss: 1.6323 - accuracy: 0.5410\n",
      "Epoch 85/100\n",
      " - 6s - loss: 1.6148 - accuracy: 0.5340\n",
      "Epoch 86/100\n",
      " - 6s - loss: 1.6056 - accuracy: 0.5220\n",
      "Epoch 87/100\n",
      " - 6s - loss: 1.5905 - accuracy: 0.5480\n",
      "Epoch 88/100\n",
      " - 6s - loss: 1.5818 - accuracy: 0.5370\n",
      "Epoch 89/100\n",
      " - 6s - loss: 1.5716 - accuracy: 0.5530\n",
      "Epoch 90/100\n",
      " - 6s - loss: 1.5567 - accuracy: 0.5460\n",
      "Epoch 91/100\n",
      " - 6s - loss: 1.5490 - accuracy: 0.5570\n",
      "Epoch 92/100\n",
      " - 6s - loss: 1.5281 - accuracy: 0.5640\n",
      "Epoch 93/100\n",
      " - 7s - loss: 1.5202 - accuracy: 0.5630\n",
      "Epoch 94/100\n",
      " - 7s - loss: 1.5245 - accuracy: 0.5510\n",
      "Epoch 95/100\n",
      " - 8s - loss: 1.4973 - accuracy: 0.5670\n",
      "Epoch 96/100\n",
      " - 7s - loss: 1.5005 - accuracy: 0.5650\n",
      "Epoch 97/100\n",
      " - 7s - loss: 1.4994 - accuracy: 0.5480\n",
      "Epoch 98/100\n",
      " - 7s - loss: 1.4650 - accuracy: 0.5790\n",
      "Epoch 99/100\n",
      " - 7s - loss: 1.4625 - accuracy: 0.5810\n",
      "Epoch 100/100\n",
      " - 7s - loss: 1.4552 - accuracy: 0.5690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x14b41259408>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(75, input_shape=(X.shape[1], X.shape[2])))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "# compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# fit model\n",
    "model.fit(X, y, epochs=100, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_trained.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 825\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# generate a sequence of characters with a language model\n",
    "def generate_seq(model, mapping, seq_length, seed_text, n_chars):\n",
    "    in_text = seed_text\n",
    "    # generate a fixed number of characters\n",
    "    for _ in range(n_chars):\n",
    "        # encode the characters as integers\n",
    "        encoded = [mapping[char] for char in in_text]\n",
    "        # truncate sequences to a fixed length\n",
    "        encoded = pad_sequences([encoded], maxlen=seq_length, truncating='pre')\n",
    "        # one hot encode\n",
    "        encoded = to_categorical(encoded, num_classes=len(mapping))\n",
    "        # predict character\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # reverse map integer to character\n",
    "        out_char = ''\n",
    "        for char, index in mapping.items():\n",
    "            if index == yhat:\n",
    "                out_char = char\n",
    "                break\n",
    "        # append to input\n",
    "        in_text += char\n",
    "    return in_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tommy Stubbins is waiting for Doctor Dolittle's return from the Moon and when the Doctor does so, h\n"
     ]
    }
   ],
   "source": [
    "input_text = summary_data[2999][:100]\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tommy Stubbins is waiting for Doctor Dolittle's return from the Moon and when the Doctor does so, higs and the pirmales\n"
     ]
    }
   ],
   "source": [
    "print(generate_seq(model, mapping, 200, input_text, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit ('msba': conda)",
   "language": "python",
   "name": "python37964bitmsbaconda92850c2aea1f40d29cc0977a921bc192"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
